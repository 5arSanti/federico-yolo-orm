{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, yaml, zipfile\n",
        "import glob\n",
        "import os, shutil, pathlib\n",
        "from utils.create_data_yaml import create_data_yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sUfcA8ZgR2t"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook uses [Ultralytics](https://docs.ultralytics.com/) to train YOLO11, YOLOv8, or YOLOv5 object detection models with a custom dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NW7LLv_QPOO"
      },
      "source": [
        "**Verify NVIDIA GPU Availability**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfaWho47RGDf",
        "outputId": "3939810c-b265-4c66-d2d3-2e512309453f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Oct 26 17:49:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1050 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |\n",
            "| 30%   27C    P8             N/A /   75W |     792MiB /   4096MiB |      1%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2360    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
            "|    0   N/A  N/A      6456    C+G   ...on\\wallpaper_engine\\wallpaper32.exe      N/A      |\n",
            "|    0   N/A  N/A     13676    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
            "|    0   N/A  N/A     13820    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
            "|    0   N/A  N/A     14976    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
            "|    0   N/A  N/A     15420    C+G   ...cw5n1h2txyewy\\CrossDeviceResume.exe      N/A      |\n",
            "|    0   N/A  N/A     17640    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
            "|    0   N/A  N/A     17684    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A     18016    C+G   ...10.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
            "|    0   N/A  N/A     18908    C+G   D:\\Program Files\\cursor\\Cursor.exe          N/A      |\n",
            "|    0   N/A  N/A     19176    C+G   ...on\\141.0.3537.99\\msedgewebview2.exe      N/A      |\n",
            "|    0   N/A  N/A     20148    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A     21396    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
            "|    0   N/A  N/A     21824    C+G   ...gine\\app-4.0.562\\RazerAppEngine.exe      N/A      |\n",
            "|    0   N/A  N/A     22200    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
            "|    0   N/A  N/A     25348    C+G   ...al\\Discord\\app-1.0.9212\\Discord.exe      N/A      |\n",
            "|    0   N/A  N/A     25572    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A     26828    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
            "|    0   N/A  N/A     27304    C+G   ...pcy8vm99wrpcg\\ModernFlyoutsHost.exe      N/A      |\n",
            "|    0   N/A  N/A     27344    C+G   C:\\Program Files\\Parsec\\parsecd.exe         N/A      |\n",
            "|    0   N/A  N/A     27876    C+G   ...23.0_x64__8wekyb3d8bbwe\\Copilot.exe      N/A      |\n",
            "|    0   N/A  N/A     30160    C+G   ...-plugins\\64bit\\obs-browser-page.exe      N/A      |\n",
            "|    0   N/A  N/A     32604    C+G   ...2.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
            "|    0   N/A  N/A     34744    C+G   ...idCam\\Client\\bin\\64bit\\droidcam.exe      N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPZEM27IOh79"
      },
      "source": [
        "**Option 1. Upload the Dataset**\n",
        "\n",
        "Upload the `data.zip` (Export from Label studio) to the root folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7Iz9eBzW5zm"
      },
      "source": [
        "## 2. Split images into train and validation folders\n",
        "Next, we'll unzip `data.zip` and create some folders to hold the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z8O6z-wVcPEF"
      },
      "outputs": [],
      "source": [
        "zip_path = \"dataset/data.zip\"\n",
        "extract_dir = \"dataset/custom_data\"\n",
        "\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoPjqW6AYebn"
      },
      "source": [
        "Afterwards and taking into account that we use Ultralytics, it is needed particular folder structure to store training data for models. The root folder is named “data”. Inside, there are two main folders:\n",
        "\n",
        "*   **Train**: These are the actual images used to train the model. In one epoch of training, every image in the train set is passed into the neural network. The training algorithm adjusts the network weights to fit the data in the images.\n",
        "\n",
        "*   **Validation**: These images are used to check the model's performance at the end of each training epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8X62eFTugosf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created folder at d:\\Todo\\Documentos\\Santiago\\3_Trabajo Profesional\\Full-Stack-Projects\\federico-yolo-orm\\data/train/images.\n",
            "Created folder at d:\\Todo\\Documentos\\Santiago\\3_Trabajo Profesional\\Full-Stack-Projects\\federico-yolo-orm\\data/train/labels.\n",
            "Created folder at d:\\Todo\\Documentos\\Santiago\\3_Trabajo Profesional\\Full-Stack-Projects\\federico-yolo-orm\\data/validation/images.\n",
            "Created folder at d:\\Todo\\Documentos\\Santiago\\3_Trabajo Profesional\\Full-Stack-Projects\\federico-yolo-orm\\data/validation/labels.\n",
            "Number of image files: 52\n",
            "Number of annotation files: 52\n",
            "Images moving to train: 46\n",
            "Images moving to validation: 6\n"
          ]
        }
      ],
      "source": [
        "!python utils/train_val_split.py --datapath=\"dataset/custom_data\" --train_pct=0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuZoMkSFN9XG"
      },
      "source": [
        "# 4.&nbsp;Configure Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5Kdh0GmQHS"
      },
      "source": [
        "There's one last step before we can run training: we need to create the Ultralytics training configuration YAML file. This file specifies the location of your train and validation data, and it also defines the model's classes.\n",
        "\n",
        "It is necessary to ensure that the Labelmap is located in `custom_data/classes.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4letvP7X12ji"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created config file at data.yaml\n",
            "\n",
            "File contents:\n",
            "\n",
            "path: data\n",
            "train: train/images\n",
            "val: validation/images\n",
            "nc: 7\n",
            "names:\n",
            "- Andrea Lopez\n",
            "- Cristhian Tapiero\n",
            "- Daniela Fierro\n",
            "- Johel Arias\n",
            "- Marcela Cifuentes\n",
            "- Mauricio Alonso\n",
            "- \"Pablo Carre\\xC3\\xB1o\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "path_to_classes_txt = 'dataset/custom_data/classes.txt'\n",
        "path_to_data_yaml = 'data.yaml'\n",
        "\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "with open(\"data.yaml\", \"r\") as f:\n",
        "    print(f.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myP80_bnTNMi"
      },
      "source": [
        "# 5.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfKspYasCzC8"
      },
      "source": [
        "## 5.1 Training Parameters\n",
        "\n",
        "**Model architecture & size (`model`):**\n",
        "\n",
        "There are several YOLO11 models sizes available to train, including `yolo11n.pt`, `yolo11s.pt`, `yolo11m.pt`, `yolo11l.pt`, and `yolo11xl.pt`. Larger models run slower but have higher accuracy, while smaller models run faster but have lower accuracy. \n",
        "\n",
        "Example: [check it out here to get a sense of their speed accuracy](https://youtu.be/_WKS4E9SmkA). \n",
        "By default, `yolo11n.pt` will be used as the starting point.\n",
        "\n",
        "We can also train with YOLOv8 or YOLOv5 models by substituting `yolo11` for `yolov8` or `yolov5`.\n",
        "\n",
        "\n",
        "**Number of epochs (`epochs`)**\n",
        "In machine learning, one “epoch” is one single pass through the full training dataset. Setting the number of epochs dictates how long the model will train for. The best amount of epochs to use depends on the size of the dataset and the model architecture. \n",
        "\n",
        "In our case we will use 60 epochs. \n",
        "If your dataset has more than 200 images, a good starting point is 40 epochs.\n",
        "\n",
        "\n",
        "**Resolution (`imgsz`)**\n",
        "Resolution has a large impact on the speed and accuracy of the model: a lower resolution model will have higher speed but less accuracy. \n",
        "YOLO models are typically trained and inferenced at a 640x640 resolution. \n",
        "\n",
        "We can choose to lower the resolution to 480x480 for better model performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQi_hXnUVPr-"
      },
      "source": [
        "model = Specifies the model to use\n",
        "epochs = Specifies the number of training epochs\n",
        "imgsz = Specifies the resolution of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8bbpob1gTPlo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"yolo\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        }
      ],
      "source": [
        "!yolo detect train data=data.yaml model=yolo11n.pt epochs=60 imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv0EYWJ5V6mC"
      },
      "source": [
        "The training algorithm will parse the images in the training and validation directories and then start training the model. \n",
        "\n",
        "At the end of each training epoch, the program runs the model on the validation dataset and reports the resulting mAP, precision, and recall. As training continues, the mAP should generally increase with each epoch. Training will end once it goes through the number of epochs specified.\n",
        "\n",
        "The best trained model weights will be saved in `content/runs/detect/train/weights/best.pt`. Additional information about training is saved in the `content/runs/detect/train` folder, including a `results.png` file that shows how loss, precision, recall, and mAP progressed over each epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo8BJRXeg0Ap"
      },
      "source": [
        "# 6.&nbsp;Test Model\n",
        "The commands below run the model on the images in the validation folder and then display the results for the first 5 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PooP5Vjsg2Jn"
      },
      "outputs": [],
      "source": [
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=data/validation/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEEObQqoiGrs"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'runs/detect/predict/*.jpg')[:5]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGiQw_gWbSBa"
      },
      "source": [
        "The model should draw a box around each object of interest in each image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yrFRViVczX"
      },
      "source": [
        "# 7.&nbsp;Deploy Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcoBAeHXa86W"
      },
      "source": [
        "## 7.1 Download YOLO Model\n",
        "\n",
        "First, zip and download the trained model by running the code blocks below.\n",
        "\n",
        "The code creates a folder named `my_model`, moves the model weights into it, and renames them from `best.pt` to `my_model.pt`, and also adds the training results for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_notebook_path():\n",
        "    return str(pathlib.Path().resolve())\n",
        "\n",
        "print(get_notebook_path())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcBdnOA9v85S"
      },
      "outputs": [],
      "source": [
        "base_dir = get_notebook_path()\n",
        "train_dir = os.path.join(base_dir, \"runs\", \"detect\", \"train\")\n",
        "output_dir = os.path.join(base_dir, \"my_model\")\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "shutil.copy(os.path.join(train_dir, \"weights\", \"best.pt\"), os.path.join(output_dir, \"my_model.pt\"))\n",
        "shutil.copytree(train_dir, os.path.join(output_dir, \"train\"), dirs_exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Using the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python utils/yolo_detect.py --model my_model/my_model.pt --source usb0 --resolution 1280x720"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fede-model-env1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
